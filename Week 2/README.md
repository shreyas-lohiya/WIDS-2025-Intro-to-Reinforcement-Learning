# Week 2
## Reading Material

- Grokking Chapter 2 - (for part 1)
- Sutton & Barto: Chapter 3 (for part 2)
- (Optional) Markov Chains extra reading material [here](./Markov_chains.pdf)

Do try to work through some of the exercises; otherwise concepts like the Bellman optimality equations may not be properly understood.

## Videos
You can refer to these videos if required 

[This lecture by David Silver](https://www.youtube.com/watch?v=_j6pvGEchWU) on MDPs and Bellman Optimality Equations. He's a computer scientist working in Google Deepmind and is one of the leading researchers in RL.

[This video](https://www.youtube.com/watch?v=_j6pvGEchWU) is much shorter, but assumes that you already know the definitions of state-value and action-value functions. It may take some time to understand, so feel free to pause and work through it carefully. For this week you only need to know until 11:25 into the video.(The remaining part of the video will be week 3 :) )

## Part 1 - Markov Decision Processes(MDPs)

The assignment in `Assignment_2.ipynb` focuses on modelling MDP environments. The goal is to help you understand how MDPs are defined and how they work. Note that most problems we work with using RL always have a MDP working under the hood, which we may or may not(most of the time) know.

There is also an **optional** reading assignment, [here](./Markov_chains.pdf) which you can read if you are intereseted in understanding of Markov chains in detail. 

Note that it requires some basic understanding of probability, expected value and random variables so its fine if you don't understand in the beginning. But it is important that you google these terms to get a basic idea if you don't know them ,as they will be used quite frequently in RL.

## Part 2 - Bellman Optimality Equations

Our goal in this part is to understand state-value functions, action-value functions, and the Bellman optimality equations, which are used to define and compute optimal value functions. 

I would recommend going through chapter 3 of Sutton and Barto once, work through exercises and if you have any doubts try and see if the videos I linked at the top can help you out.